# neurocti
An LLM for CTI reports: fine-tuning LLMs for working with CTI reports

# neurocti-small

The [neurocti-small](../neurocti-small) mode is built on top of llama-3.1.

# How to train the models yourself

We aim at replicability and you being able to train your own models as much as possible.
Please see the [training.md](training.md) HOWTO.

# How to run them


# Past presentations
* [Annual FIRST conference](https://www.first.org/conference/2024/program#pNeuroCTI-a-Custom-Fine-Tuned-LLM-for-CTI-Benchmarking-Successes-and-Lessons-Learned) Fukuoka, Japan 2024: [slides](https://www.first.org/resources/papers/conf2024/1115-Neurocti-Kaplan-Dulaunoy-Brandl.pdf)
* Hack.lu 2024: [video](https://youtu.be/sVlLjaTY1pc?feature=shared)
* CERT-Stammtisch 2024: [slides]()
* BSides 2024 Vienna: [slides]()
